# 1
# ç¯å¢ƒæ£€æŸ¥
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path.cwd().parent
sys.path.insert(0, str(project_root / "src"))

# æ ¸å¿ƒåº“å¯¼å…¥
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings('ignore')

# é¡¹ç›®æ¨¡å—å¯¼å…¥
from feature_extraction import PeptideFeaturizer
from feature_extraction.utils import (
    get_csv_files, load_csv_safely, extract_molecular_features,
    convert_label_to_minutes, save_features_to_npz
)

# è®¾ç½®æ˜¾ç¤ºé€‰é¡¹
pd.set_option('display.max_columns', None)
plt.rcParams['figure.figsize'] = (12, 6)
sns.set_style('whitegrid')

print("âœ“ æ‰€æœ‰åº“å·²æˆåŠŸå¯¼å…¥")
print(f"âœ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")





# ============== å‚æ•°é…ç½®åŒº ==============
# ç”¨æˆ·å¯æ ¹æ®éœ€è¦ä¿®æ”¹ä»¥ä¸‹å‚æ•°

CONFIG = {
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    'raw_dir': project_root / 'data' / 'raw',
    'processed_dir': project_root / 'data' / 'processed',
    'features_dir': project_root / 'outputs' / 'features',
    'figures_dir': project_root / 'outputs' / 'figures' / 'phase1',
    
    # ç‰¹å¾æå–å‚æ•°
    'morgan_bits': 1024,     # MorganæŒ‡çº¹ä½æ•°
    'avalon_bits': 512,      # AvalonæŒ‡çº¹ä½æ•°
    'use_avalon': True,      # æ˜¯å¦ä½¿ç”¨AvalonæŒ‡çº¹ï¼ˆéœ€RDKitæ”¯æŒï¼‰
    
    # å¯è§†åŒ–å‚æ•°
    'dpi': 300,              # å›¾åƒåˆ†è¾¨ç‡
    'format': 'png',         # å›¾åƒæ ¼å¼ (png/pdf/svg)
    'display_plots': True,   # æ˜¯å¦åœ¨notebookä¸­æ˜¾ç¤ºå…³é”®å›¾è¡¨
    'max_display_plots': 3,  # æœ€å¤šæ˜¾ç¤ºå‡ ä¸ªå›¾è¡¨
}

# åˆ›å»ºè¾“å‡ºç›®å½•
CONFIG['processed_dir'].mkdir(parents=True, exist_ok=True)
CONFIG['features_dir'].mkdir(parents=True, exist_ok=True)
CONFIG['figures_dir'].mkdir(parents=True, exist_ok=True)

print("é…ç½®å‚æ•°:")
for key, value in CONFIG.items():
    if isinstance(value, Path):
        print(f"  {key}: {value.relative_to(project_root) if value.is_relative_to(project_root) else value}")
    else:
        print(f"  {key}: {value}")




def add_molecular_features_to_csv(csv_path: Path, output_dir: Path):
    """
    ä¸ºå•ä¸ªCSVæ–‡ä»¶æ·»åŠ åˆ†å­ç‰¹å¾
    
    Args:
        csv_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    # åŠ è½½CSV
    df, status = load_csv_safely(csv_path, required_columns=["id", "SMILES"])
    if df is None:
        return {"error": status}
    
    original_count = len(df)
    
    # æå–åˆ†å­ç‰¹å¾
    feature_records = []
    for _, row in tqdm(df.iterrows(), total=len(df), desc=f"å¤„ç† {csv_path.name}", leave=False):
        smiles = row["SMILES"]
        features = extract_molecular_features(smiles)
        feature_records.append(features)
    
    # æ·»åŠ ç‰¹å¾åˆ—
    feature_df = pd.DataFrame(feature_records)
    df = pd.concat([df, feature_df], axis=1)
    
    # è½¬æ¢æ ‡ç­¾åˆ°åˆ†é’Ÿ
    sif_col = "SIF_class" if "SIF_class" in df.columns else None
    sgf_col = "SGF_class" if "SGF_class" in df.columns else None
    
    if sif_col:
        df["SIF_minutes"] = df[sif_col].apply(convert_label_to_minutes)
    else:
        df["SIF_minutes"] = -1
    
    if sgf_col:
        df["SGF_minutes"] = df[sgf_col].apply(convert_label_to_minutes)
    else:
        df["SGF_minutes"] = -1
    
    # è¿‡æ»¤åŒæ ‡ç­¾ç¼ºå¤±çš„æ ·æœ¬
    mask_both_missing = (df["SIF_minutes"] == -1) & (df["SGF_minutes"] == -1)
    df_filtered = df[~mask_both_missing].copy()
    
    # ä¿å­˜å¤„ç†åçš„CSV
    output_path = output_dir / csv_path.name.replace('.csv', '_processed.csv')
    df_filtered.to_csv(output_path, index=False)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "file": csv_path.name,
        "original_count": original_count,
        "filtered_count": len(df_filtered),
        "dimer_count": df_filtered["is_dimer"].sum(),
        "cyclic_count": df_filtered["is_cyclic"].sum(),
        "disulfide_count": df_filtered["has_disulfide_bond"].sum(),
        "sif_valid_count": (df_filtered["SIF_minutes"] != -1).sum(),
        "sgf_valid_count": (df_filtered["SGF_minutes"] != -1).sum(),
        "output_path": output_path,
    }
    
    return stats

# æ‰§è¡Œï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰CSVæ–‡ä»¶
csv_files = list(CONFIG['raw_dir'].glob('*.csv'))
print(f"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶\n")

all_stats = []
for csv_file in csv_files:
    stats = add_molecular_features_to_csv(csv_file, CONFIG['processed_dir'])
    if "error" not in stats:
        all_stats.append(stats)
        print(f"âœ“ {stats['file']}: {stats['original_count']} â†’ {stats['filtered_count']} samples")

# æ±‡æ€»ç»Ÿè®¡
summary_df = pd.DataFrame(all_stats)
print(f"\n{'='*60}")
print("æ€»ä½“ç»Ÿè®¡:")
print(f"  æ€»æ ·æœ¬æ•°: {summary_df['original_count'].sum()}")
print(f"  ä¿ç•™æ ·æœ¬æ•°: {summary_df['filtered_count'].sum()} ({summary_df['filtered_count'].sum() / summary_df['original_count'].sum() * 100:.1f}%)")
print(f"  äºŒèšä½“æ ·æœ¬: {summary_df['dimer_count'].sum()} ({summary_df['dimer_count'].sum() / summary_df['filtered_count'].sum() * 100:.1f}%)")
print(f"  ç¯åŒ–æ ·æœ¬: {summary_df['cyclic_count'].sum()} ({summary_df['cyclic_count'].sum() / summary_df['filtered_count'].sum() * 100:.1f}%)")
print(f"  å«äºŒç¡«é”®æ ·æœ¬: {summary_df['disulfide_count'].sum()} ({summary_df['disulfide_count'].sum() / summary_df['filtered_count'].sum() * 100:.1f}%)")
print(f"{'='*60}\n")

# æ˜¾ç¤ºè¯¦ç»†è¡¨æ ¼
display(summary_df[['file', 'original_count', 'filtered_count', 'dimer_count', 'cyclic_count', 'disulfide_count']])





from pathlib import Path
def extract_rdkit_features(csv_path: Path, output_dir: Path, featurizer):
    """
    ä»CSVæå–RDKitç‰¹å¾å¹¶ä¿å­˜ä¸ºNPZ
    
    Args:
        csv_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        featurizer: PeptideFeaturizerå®ä¾‹
    
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    # åŠ è½½CSV
    df, _ = load_csv_safely(csv_path, required_columns=["id", "SMILES", "SIF_minutes", "SGF_minutes"])
    if df is None:
        return {"error": "Failed to load CSV"}
    
    X = []
    y_sif = []
    y_sgf = []
    ids = []
    valid_count = 0
    
    # æå–ç‰¹å¾
    for _, row in tqdm(df.iterrows(), total=len(df), desc=f"æå–ç‰¹å¾ {csv_path.name}", leave=False):
        smiles = str(row["SMILES"])
        features, success = featurizer.featurize(smiles)
        
        if success and features is not None:
            X.append(features)
            y_sif.append(int(row["SIF_minutes"]) if not pd.isna(row["SIF_minutes"]) else -1)
            y_sgf.append(int(row["SGF_minutes"]) if not pd.isna(row["SGF_minutes"]) else -1)
            ids.append(str(row["id"]))
            valid_count += 1
    
    # è½¬æ¢ä¸ºNumPyæ•°ç»„
    X = np.array(X, dtype=np.float32)
    y_sif = np.array(y_sif, dtype=np.int32)
    y_sgf = np.array(y_sgf, dtype=np.int32)
    ids = np.array(ids, dtype=object)
    feature_names = featurizer.get_feature_names()
    
    # ä¿å­˜NPZ
    output_path = output_dir / csv_path.name.replace('.csv', '.npz')
    np.savez_compressed(
        output_path,
        X=X,
        y_sif=y_sif,
        y_sgf=y_sgf,
        ids=ids,
        feature_names=feature_names,
    )
    
    return {
        "file": csv_path.name,
        "total_samples": len(df),
        "valid_samples": valid_count,
        "feature_dim": X.shape[1],
        "output_path": output_path,
    }

# åˆå§‹åŒ–ç‰¹å¾æå–å™¨
featurizer = PeptideFeaturizer(
    morgan_bits=CONFIG['morgan_bits'],
    avalon_bits=CONFIG['avalon_bits'],
    use_avalon=CONFIG['use_avalon']
)

print(f"ç‰¹å¾æå–å™¨é…ç½®:")
print(f"  MorganæŒ‡çº¹: {CONFIG['morgan_bits']} bits")
print(f"  AvalonæŒ‡çº¹: {CONFIG['avalon_bits']} bits (å¯ç”¨: {CONFIG['use_avalon']})")
print(f"  é¢„è®¡æ€»ç‰¹å¾ç»´åº¦: {featurizer.n_features}\n")

# æ‰§è¡Œï¼šæ‰¹é‡æå–ç‰¹å¾
processed_csvs = list(CONFIG['processed_dir'].glob('*_processed.csv'))
print(f"æ‰¾åˆ° {len(processed_csvs)} ä¸ªå¤„ç†åçš„CSVæ–‡ä»¶\n")

feature_stats = []
for csv_file in processed_csvs:
    stats = extract_rdkit_features(csv_file, CONFIG['features_dir'], featurizer)
    if "error" not in stats:
        feature_stats.append(stats)
        print(f"âœ“ {stats['file']}: {stats['valid_samples']} samples, {stats['feature_dim']} features")

# æ±‡æ€»
feat_summary_df = pd.DataFrame(feature_stats)
print(f"\n{'='*60}")
print("ç‰¹å¾æå–æ€»ç»“:")
print(f"  æ€»æ ·æœ¬æ•°: {feat_summary_df['valid_samples'].sum()}")
print(f"  ç‰¹å¾ç»´åº¦: {feat_summary_df['feature_dim'].iloc[0]}")
print(f"{'='*60}\n")

display(feat_summary_df[['file', 'total_samples', 'valid_samples', 'feature_dim']])







# ç®€åŒ–çš„è´¨é‡éªŒè¯ï¼šå±•ç¤ºæ•°æ®è¿‡æ»¤æµç¨‹å’Œç‰¹å¾åˆ†å¸ƒ
from IPython.display import Image as IPImage, display as ipy_display

# 1. æ•°æ®è¿‡æ»¤æµç¨‹æ¡‘åŸºå›¾ï¼ˆç®€åŒ–ç‰ˆï¼šæ¡å½¢å›¾ï¼‰
fig, ax = plt.subplots(figsize=(10, 6))

datasets = summary_df['file'].str.replace('_processed.csv', '').str.replace('.csv', '').tolist()
original = summary_df['original_count'].tolist()
filtered = summary_df['filtered_count'].tolist()

x = np.arange(len(datasets))
width = 0.35

ax.bar(x - width/2, original, width, label='åŸå§‹æ ·æœ¬', alpha=0.7)
ax.bar(x + width/2, filtered, width, label='ä¿ç•™æ ·æœ¬', alpha=0.7)

ax.set_xlabel('æ•°æ®é›†', fontsize=12)
ax.set_ylabel('æ ·æœ¬æ•°', fontsize=12)
ax.set_title('Phase 1: æ•°æ®è¿‡æ»¤ç»Ÿè®¡', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(datasets, rotation=45, ha='right')
ax.legend()
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
filter_plot_path = CONFIG['figures_dir'] / 'data_filtering_summary.png'
plt.savefig(filter_plot_path, dpi=CONFIG['dpi'], bbox_inches='tight')
print(f"âœ“ å·²ä¿å­˜: {filter_plot_path.name}")

if CONFIG['display_plots']:
    plt.show()
else:
    plt.close()

# 2. ç»“æ„ç‰¹å¾åˆ†å¸ƒå †å æ¡å½¢å›¾
fig, ax = plt.subplots(figsize=(10, 6))

dimer_pct = (summary_df['dimer_count'] / summary_df['filtered_count'] * 100).tolist()
cyclic_pct = (summary_df['cyclic_count'] / summary_df['filtered_count'] * 100).tolist()
disulfide_pct = (summary_df['disulfide_count'] / summary_df['filtered_count'] * 100).tolist()

x = np.arange(len(datasets))
ax.bar(x, dimer_pct, label='äºŒèšä½“ %', alpha=0.8)
ax.bar(x, cyclic_pct, bottom=dimer_pct, label='ç¯åŒ– %', alpha=0.8)
ax.bar(x, disulfide_pct, bottom=np.array(dimer_pct) + np.array(cyclic_pct), label='äºŒç¡«é”® %', alpha=0.8)

ax.set_xlabel('æ•°æ®é›†', fontsize=12)
ax.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
ax.set_title('Phase 1: ç»“æ„ç‰¹å¾åˆ†å¸ƒ', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(datasets, rotation=45, ha='right')
ax.legend()
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
feature_plot_path = CONFIG['figures_dir'] / 'structural_features_distribution.png'
plt.savefig(feature_plot_path, dpi=CONFIG['dpi'], bbox_inches='tight')
print(f"âœ“ å·²ä¿å­˜: {feature_plot_path.name}")

if CONFIG['display_plots']:
    plt.show()
else:
    plt.close()

print(f"\nâœ“ Phase 1 è´¨é‡éªŒè¯å®Œæˆï¼")
print(f"  æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {CONFIG['figures_dir'].relative_to(project_root)}")



print("="*70)
print("Phase 1: æ•°æ®è½¬åŒ– - æ‰§è¡Œå®Œæ¯•")
print("="*70)

print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"\n  1. å¤„ç†åçš„CSV ({len(list(CONFIG['processed_dir'].glob('*.csv')))} ä¸ªæ–‡ä»¶):")
for f in sorted(CONFIG['processed_dir'].glob('*_processed.csv')):
    print(f"     - {f.name}")

print(f"\n  2. ç‰¹å¾NPZæ–‡ä»¶ ({len(list(CONFIG['features_dir'].glob('*.npz')))} ä¸ªæ–‡ä»¶):")
for f in sorted(CONFIG['features_dir'].glob('*.npz')):
    size_mb = f.stat().st_size / 1024 / 1024
    print(f"     - {f.name} ({size_mb:.2f} MB)")

print(f"\n  3. éªŒè¯å›¾è¡¨ ({len(list(CONFIG['figures_dir'].glob('*.png')))} ä¸ªæ–‡ä»¶):")
for f in sorted(CONFIG['figures_dir'].glob('*.png')):
    print(f"     - {f.name}")

print("\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
total_original = summary_df['original_count'].sum()
total_filtered = summary_df['filtered_count'].sum()
retention_rate = total_filtered / total_original * 100

print(f"  åŸå§‹æ ·æœ¬æ€»æ•°: {total_original:,}")
print(f"  ä¿ç•™æ ·æœ¬æ€»æ•°: {total_filtered:,} ({retention_rate:.1f}%)")
print(f"  è¿‡æ»¤æ ·æœ¬æ•°: {total_original - total_filtered:,} ({100-retention_rate:.1f}%)")
print(f"\n  äºŒèšä½“æ ·æœ¬: {summary_df['dimer_count'].sum()} ({summary_df['dimer_count'].sum()/total_filtered*100:.1f}%)")
print(f"  ç¯åŒ–æ ·æœ¬: {summary_df['cyclic_count'].sum()} ({summary_df['cyclic_count'].sum()/total_filtered*100:.1f}%)")
print(f"  å«äºŒç¡«é”®æ ·æœ¬: {summary_df['disulfide_count'].sum()} ({summary_df['disulfide_count'].sum()/total_filtered*100:.1f}%)")

print(f"\nâœ… ä¸‹ä¸€æ­¥: è¿è¡Œ Phase2_æ•°æ®å¯è§†åŒ–.ipynb")
print("="*70)
