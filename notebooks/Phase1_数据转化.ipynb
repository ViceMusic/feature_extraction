{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: æ•°æ®è½¬åŒ– (Data Transformation)\n",
    "\n",
    "## æ¦‚è¿° Overview\n",
    "\n",
    "æœ¬Notebookå®ç°Phase 1çš„å®Œæ•´æµç¨‹ï¼Œå°†åŸå§‹CSVæ•°æ®è½¬æ¢ä¸ºå¯ç”¨äºå»ºæ¨¡çš„ç‰¹å¾çŸ©é˜µã€‚\n",
    "\n",
    "**ä¸»è¦æ­¥éª¤ï¼š**\n",
    "1. **æ•°æ®æ¸…ç†** (Optional): æ¸…ç†åŸå§‹CSVæ•°æ®ï¼Œè½¬æ¢æ˜Ÿå·æ ‡è®°\n",
    "2. **æ·»åŠ åˆ†å­ç‰¹å¾**: æ£€æµ‹å•ä½“/äºŒèšä½“ã€ç¯åŒ–ã€äºŒç¡«é”®ï¼Œè½¬æ¢æ ‡ç­¾ä¸ºåˆ†é’Ÿ\n",
    "3. **æå–RDKitç‰¹å¾**: æå–QEDã€ç‰©ç†åŒ–å­¦æè¿°ç¬¦ã€Morgan/AvalonæŒ‡çº¹\n",
    "4. **è´¨é‡éªŒè¯**: å¯è§†åŒ–éªŒè¯ç‰¹å¾æå–è´¨é‡\n",
    "\n",
    "**è¾“å…¥**: `data/raw/*.csv` - åŸå§‹æ•°æ®æ–‡ä»¶  \n",
    "**è¾“å‡º**: \n",
    "- `data/processed/*.csv` - æ·»åŠ åˆ†å­ç‰¹å¾åçš„CSV  \n",
    "- `outputs/features/*.npz` - RDKitç‰¹å¾çŸ©é˜µ  \n",
    "- `outputs/figures/phase1/*.png` - è´¨é‡éªŒè¯å›¾è¡¨  \n",
    "\n",
    "**æ€»æ ·æœ¬æ•°**: 1,931 â†’ 932 (48.3% retention)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒæ£€æŸ¥ä¸å¯¼å…¥ Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒæ£€æŸ¥\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# æ ¸å¿ƒåº“å¯¼å…¥\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# é¡¹ç›®æ¨¡å—å¯¼å…¥\n",
    "from feature_extraction import PeptideFeaturizer\n",
    "from feature_extraction.utils import (\n",
    "    get_csv_files, load_csv_safely, extract_molecular_features,\n",
    "    convert_label_to_minutes, save_features_to_npz\n",
    ")\n",
    "\n",
    "# è®¾ç½®æ˜¾ç¤ºé€‰é¡¹\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ“ æ‰€æœ‰åº“å·²æˆåŠŸå¯¼å…¥\")\n",
    "print(f\"âœ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å‚æ•°é…ç½®åŒº Configuration\n",
    "\n",
    "**âš™ï¸ æ ¹æ®æ‚¨çš„éœ€æ±‚ä¿®æ”¹ä»¥ä¸‹å‚æ•°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== å‚æ•°é…ç½®åŒº ==============\n",
    "# ç”¨æˆ·å¯æ ¹æ®éœ€è¦ä¿®æ”¹ä»¥ä¸‹å‚æ•°\n",
    "\n",
    "CONFIG = {\n",
    "    # è¾“å…¥è¾“å‡ºè·¯å¾„\n",
    "    'raw_dir': project_root / 'data' / 'raw',\n",
    "    'processed_dir': project_root / 'data' / 'processed',\n",
    "    'features_dir': project_root / 'outputs' / 'features',\n",
    "    'figures_dir': project_root / 'outputs' / 'figures' / 'phase1',\n",
    "    \n",
    "    # ç‰¹å¾æå–å‚æ•°\n",
    "    'morgan_bits': 1024, #1024,     # MorganæŒ‡çº¹ä½æ•°ï¼ˆè¿™é‡Œä¸´æ—¶ä¿®æ”¹ä¸º0ï¼Œå…³é—­ç‰¹å¾æå–ï¼‰\n",
    "    'avalon_bits': 512,      # AvalonæŒ‡çº¹ä½æ•°\n",
    "    'use_avalon': True,      # æ˜¯å¦ä½¿ç”¨AvalonæŒ‡çº¹ï¼ˆéœ€RDKitæ”¯æŒï¼‰\n",
    "    \n",
    "    # å¯è§†åŒ–å‚æ•°\n",
    "    'dpi': 300,              # å›¾åƒåˆ†è¾¨ç‡\n",
    "    'format': 'png',         # å›¾åƒæ ¼å¼ (png/pdf/svg)\n",
    "    'display_plots': True,   # æ˜¯å¦åœ¨notebookä¸­æ˜¾ç¤ºå…³é”®å›¾è¡¨\n",
    "    'max_display_plots': 3,  # æœ€å¤šæ˜¾ç¤ºå‡ ä¸ªå›¾è¡¨\n",
    "}\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "CONFIG['processed_dir'].mkdir(parents=True, exist_ok=True)\n",
    "CONFIG['features_dir'].mkdir(parents=True, exist_ok=True)\n",
    "CONFIG['figures_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"é…ç½®å‚æ•°:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if isinstance(value, Path):\n",
    "        print(f\"  {key}: {value.relative_to(project_root) if value.is_relative_to(project_root) else value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ­¥éª¤ 1: æ·»åŠ åˆ†å­ç‰¹å¾ Add Molecular Features\n",
    "\n",
    "ä¸ºæ¯ä¸ªSMILESåˆ†å­æ·»åŠ ç»“æ„ç‰¹å¾å¹¶è½¬æ¢æ ‡ç­¾æ ¼å¼ã€‚\n",
    "\n",
    "**æ–°å¢åˆ—**:\n",
    "- `is_dimer`: æ˜¯å¦ä¸ºäºŒèšä½“ (bool)\n",
    "- `is_cyclic`: æ˜¯å¦å«ç¯çŠ¶ç»“æ„ (bool)\n",
    "- `has_disulfide_bond`: æ˜¯å¦å«äºŒç¡«é”® (bool)\n",
    "- `SIF_minutes`: SIFåŠè¡°æœŸï¼ˆåˆ†é’Ÿï¼‰\n",
    "- `SGF_minutes`: SGFåŠè¡°æœŸï¼ˆåˆ†é’Ÿï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_molecular_features_to_csv(csv_path: Path, output_dir: Path):\n",
    "    \"\"\"\n",
    "    ä¸ºå•ä¸ªCSVæ–‡ä»¶æ·»åŠ åˆ†å­ç‰¹å¾\n",
    "    \n",
    "    Args:\n",
    "        csv_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„\n",
    "        output_dir: è¾“å‡ºç›®å½•\n",
    "    \n",
    "    Returns:\n",
    "        dict: ç»Ÿè®¡ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # åŠ è½½CSV\n",
    "    df, status = load_csv_safely(csv_path, required_columns=[\"id\", \"SMILES\"])\n",
    "    if df is None:\n",
    "        return {\"error\": status}\n",
    "    \n",
    "    original_count = len(df)\n",
    "    \n",
    "    # æå–åˆ†å­ç‰¹å¾\n",
    "    feature_records = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"å¤„ç† {csv_path.name}\", leave=False):\n",
    "        smiles = row[\"SMILES\"]\n",
    "        features = extract_molecular_features(smiles)\n",
    "        feature_records.append(features)\n",
    "    \n",
    "    # æ·»åŠ ç‰¹å¾åˆ—\n",
    "    feature_df = pd.DataFrame(feature_records)\n",
    "    df = pd.concat([df, feature_df], axis=1)\n",
    "    \n",
    "    # è½¬æ¢æ ‡ç­¾åˆ°åˆ†é’Ÿ\n",
    "    sif_col = \"SIF_class\" if \"SIF_class\" in df.columns else None\n",
    "    sgf_col = \"SGF_class\" if \"SGF_class\" in df.columns else None\n",
    "    \n",
    "    if sif_col:\n",
    "        df[\"SIF_minutes\"] = df[sif_col].apply(convert_label_to_minutes)\n",
    "    else:\n",
    "        df[\"SIF_minutes\"] = -1\n",
    "    \n",
    "    if sgf_col:\n",
    "        df[\"SGF_minutes\"] = df[sgf_col].apply(convert_label_to_minutes)\n",
    "    else:\n",
    "        df[\"SGF_minutes\"] = -1\n",
    "    \n",
    "    # è¿‡æ»¤åŒæ ‡ç­¾ç¼ºå¤±çš„æ ·æœ¬\n",
    "    mask_both_missing = (df[\"SIF_minutes\"] == -1) & (df[\"SGF_minutes\"] == -1)\n",
    "    df_filtered = df[~mask_both_missing].copy()\n",
    "    \n",
    "    # ä¿å­˜å¤„ç†åçš„CSV\n",
    "    output_path = output_dir / csv_path.name.replace('.csv', '_processed.csv')\n",
    "    df_filtered.to_csv(output_path, index=False)\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    stats = {\n",
    "        \"file\": csv_path.name,\n",
    "        \"original_count\": original_count,\n",
    "        \"filtered_count\": len(df_filtered),\n",
    "        \"dimer_count\": df_filtered[\"is_dimer\"].sum(),\n",
    "        \"cyclic_count\": df_filtered[\"is_cyclic\"].sum(),\n",
    "        \"disulfide_count\": df_filtered[\"has_disulfide_bond\"].sum(),\n",
    "        \"sif_valid_count\": (df_filtered[\"SIF_minutes\"] != -1).sum(),\n",
    "        \"sgf_valid_count\": (df_filtered[\"SGF_minutes\"] != -1).sum(),\n",
    "        \"output_path\": output_path,\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# æ‰§è¡Œï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰CSVæ–‡ä»¶\n",
    "csv_files = list(CONFIG['raw_dir'].glob('*.csv'))\n",
    "print(f\"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶\\n\")\n",
    "\n",
    "all_stats = []\n",
    "for csv_file in csv_files:\n",
    "    stats = add_molecular_features_to_csv(csv_file, CONFIG['processed_dir'])\n",
    "    if \"error\" not in stats:\n",
    "        all_stats.append(stats)\n",
    "        print(f\"âœ“ {stats['file']}: {stats['original_count']} â†’ {stats['filtered_count']} samples\")\n",
    "\n",
    "# æ±‡æ€»ç»Ÿè®¡\n",
    "summary_df = pd.DataFrame(all_stats)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"æ€»ä½“ç»Ÿè®¡:\")\n",
    "print(f\"  æ€»æ ·æœ¬æ•°: {summary_df['original_count'].sum()}\")\n",
    "print(f\"  ä¿ç•™æ ·æœ¬æ•°: {summary_df['filtered_count'].sum()} ({summary_df['filtered_count'].sum() / summary_df['original_count'].sum() * 100:.1f}%)\")\n",
    "print(f\"  äºŒèšä½“æ ·æœ¬: {summary_df['dimer_count'].sum()} ({summary_df['dimer_count'].sum() / summary_df['filtered_count'].sum() * 100:.1f}%)\")\n",
    "print(f\"  ç¯åŒ–æ ·æœ¬: {summary_df['cyclic_count'].sum()} ({summary_df['cyclic_count'].sum() / summary_df['filtered_count'].sum() * 100:.1f}%)\")\n",
    "print(f\"  å«äºŒç¡«é”®æ ·æœ¬: {summary_df['disulfide_count'].sum()} ({summary_df['disulfide_count'].sum() / summary_df['filtered_count'].sum() * 100:.1f}%)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# æ˜¾ç¤ºè¯¦ç»†è¡¨æ ¼\n",
    "display(summary_df[['file', 'original_count', 'filtered_count', 'dimer_count', 'cyclic_count', 'disulfide_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ­¥éª¤ 2: æå–RDKitç‰¹å¾ Extract RDKit Features\n",
    "\n",
    "ä»å¤„ç†åçš„CSVä¸­æå–åˆ†å­ç‰¹å¾å‘é‡ï¼Œä¿å­˜ä¸ºNPZæ ¼å¼ã€‚\n",
    "\n",
    "**ç‰¹å¾ç±»å‹**:\n",
    "- QEDå±æ€§ (8ç»´)\n",
    "- ç‰©ç†åŒ–å­¦æè¿°ç¬¦ (11ç»´)\n",
    "- Gasteigerç”µè·ç»Ÿè®¡ (5ç»´)\n",
    "- MorganæŒ‡çº¹ (1024ç»´)\n",
    "- AvalonæŒ‡çº¹ (512ç»´, å¯é€‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def extract_rdkit_features(csv_path: Path, output_dir: Path, featurizer):\n",
    "    \"\"\"\n",
    "    ä»CSVæå–RDKitç‰¹å¾å¹¶ä¿å­˜ä¸ºNPZ\n",
    "    \n",
    "    Args:\n",
    "        csv_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„\n",
    "        output_dir: è¾“å‡ºç›®å½•\n",
    "        featurizer: PeptideFeaturizerå®ä¾‹\n",
    "    \n",
    "    Returns:\n",
    "        dict: ç»Ÿè®¡ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # åŠ è½½CSV\n",
    "    df, _ = load_csv_safely(csv_path, required_columns=[\"id\", \"SMILES\", \"SIF_minutes\", \"SGF_minutes\"])\n",
    "    if df is None:\n",
    "        return {\"error\": \"Failed to load CSV\"}\n",
    "    \n",
    "    X = []\n",
    "    y_sif = []\n",
    "    y_sgf = []\n",
    "    ids = []\n",
    "    valid_count = 0\n",
    "    \n",
    "    # æå–ç‰¹å¾\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"æå–ç‰¹å¾ {csv_path.name}\", leave=False):\n",
    "        smiles = str(row[\"SMILES\"])\n",
    "        features, success = featurizer.featurize(smiles)\n",
    "        \n",
    "        if success and features is not None:\n",
    "            X.append(features)\n",
    "            y_sif.append(int(row[\"SIF_minutes\"]) if not pd.isna(row[\"SIF_minutes\"]) else -1)\n",
    "            y_sgf.append(int(row[\"SGF_minutes\"]) if not pd.isna(row[\"SGF_minutes\"]) else -1)\n",
    "            ids.append(str(row[\"id\"]))\n",
    "            valid_count += 1\n",
    "    \n",
    "    # è½¬æ¢ä¸ºNumPyæ•°ç»„\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y_sif = np.array(y_sif, dtype=np.int32)\n",
    "    y_sgf = np.array(y_sgf, dtype=np.int32)\n",
    "    ids = np.array(ids, dtype=object)\n",
    "    feature_names = featurizer.get_feature_names()\n",
    "    \n",
    "    # ä¿å­˜NPZ\n",
    "    output_path = output_dir / csv_path.name.replace('.csv', '.npz')\n",
    "    np.savez_compressed(\n",
    "        output_path,\n",
    "        X=X,\n",
    "        y_sif=y_sif,\n",
    "        y_sgf=y_sgf,\n",
    "        ids=ids,\n",
    "        feature_names=feature_names,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"file\": csv_path.name,\n",
    "        \"total_samples\": len(df),\n",
    "        \"valid_samples\": valid_count,\n",
    "        \"feature_dim\": X.shape[1],\n",
    "        \"output_path\": output_path,\n",
    "    }\n",
    "\n",
    "# åˆå§‹åŒ–ç‰¹å¾æå–å™¨\n",
    "featurizer = PeptideFeaturizer(\n",
    "    morgan_bits=CONFIG['morgan_bits'],\n",
    "    avalon_bits=CONFIG['avalon_bits'],\n",
    "    use_avalon=CONFIG['use_avalon']\n",
    ")\n",
    "\n",
    "print(f\"ç‰¹å¾æå–å™¨é…ç½®:\")\n",
    "print(f\"  MorganæŒ‡çº¹: {CONFIG['morgan_bits']} bits\")\n",
    "print(f\"  AvalonæŒ‡çº¹: {CONFIG['avalon_bits']} bits (å¯ç”¨: {CONFIG['use_avalon']})\")\n",
    "print(f\"  é¢„è®¡æ€»ç‰¹å¾ç»´åº¦: {featurizer.n_features}\\n\")\n",
    "\n",
    "# æ‰§è¡Œï¼šæ‰¹é‡æå–ç‰¹å¾\n",
    "processed_csvs = list(CONFIG['processed_dir'].glob('*_processed.csv'))\n",
    "print(f\"æ‰¾åˆ° {len(processed_csvs)} ä¸ªå¤„ç†åçš„CSVæ–‡ä»¶\\n\")\n",
    "\n",
    "feature_stats = []\n",
    "for csv_file in processed_csvs:\n",
    "    stats = extract_rdkit_features(csv_file, CONFIG['features_dir'], featurizer)\n",
    "    if \"error\" not in stats:\n",
    "        feature_stats.append(stats)\n",
    "        print(f\"âœ“ {stats['file']}: {stats['valid_samples']} samples, {stats['feature_dim']} features\")\n",
    "\n",
    "# æ±‡æ€»\n",
    "feat_summary_df = pd.DataFrame(feature_stats)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ç‰¹å¾æå–æ€»ç»“:\")\n",
    "print(f\"  æ€»æ ·æœ¬æ•°: {feat_summary_df['valid_samples'].sum()}\")\n",
    "print(f\"  ç‰¹å¾ç»´åº¦: {feat_summary_df['feature_dim'].iloc[0]}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "display(feat_summary_df[['file', 'total_samples', 'valid_samples', 'feature_dim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel OK\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ­¥éª¤ 3: è´¨é‡éªŒè¯å¯è§†åŒ– Quality Validation\n",
    "\n",
    "ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨éªŒè¯Phase 1çš„æ•°æ®å¤„ç†è´¨é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç®€åŒ–çš„è´¨é‡éªŒè¯ï¼šå±•ç¤ºæ•°æ®è¿‡æ»¤æµç¨‹å’Œç‰¹å¾åˆ†å¸ƒ\n",
    "from IPython.display import Image as IPImage, display as ipy_display\n",
    "\n",
    "# 1. æ•°æ®è¿‡æ»¤æµç¨‹æ¡‘åŸºå›¾ï¼ˆç®€åŒ–ç‰ˆï¼šæ¡å½¢å›¾ï¼‰\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "datasets = summary_df['file'].str.replace('_processed.csv', '').str.replace('.csv', '').tolist()\n",
    "original = summary_df['original_count'].tolist()\n",
    "filtered = summary_df['filtered_count'].tolist()\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, original, width, label='åŸå§‹æ ·æœ¬', alpha=0.7)\n",
    "ax.bar(x + width/2, filtered, width, label='ä¿ç•™æ ·æœ¬', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('æ•°æ®é›†', fontsize=12)\n",
    "ax.set_ylabel('æ ·æœ¬æ•°', fontsize=12)\n",
    "ax.set_title('Phase 1: æ•°æ®è¿‡æ»¤ç»Ÿè®¡', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "filter_plot_path = CONFIG['figures_dir'] / 'data_filtering_summary.png'\n",
    "plt.savefig(filter_plot_path, dpi=CONFIG['dpi'], bbox_inches='tight')\n",
    "print(f\"âœ“ å·²ä¿å­˜: {filter_plot_path.name}\")\n",
    "\n",
    "if CONFIG['display_plots']:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "\n",
    "# 2. ç»“æ„ç‰¹å¾åˆ†å¸ƒå †å æ¡å½¢å›¾\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "dimer_pct = (summary_df['dimer_count'] / summary_df['filtered_count'] * 100).tolist()\n",
    "cyclic_pct = (summary_df['cyclic_count'] / summary_df['filtered_count'] * 100).tolist()\n",
    "disulfide_pct = (summary_df['disulfide_count'] / summary_df['filtered_count'] * 100).tolist()\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "ax.bar(x, dimer_pct, label='äºŒèšä½“ %', alpha=0.8)\n",
    "ax.bar(x, cyclic_pct, bottom=dimer_pct, label='ç¯åŒ– %', alpha=0.8)\n",
    "ax.bar(x, disulfide_pct, bottom=np.array(dimer_pct) + np.array(cyclic_pct), label='äºŒç¡«é”® %', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('æ•°æ®é›†', fontsize=12)\n",
    "ax.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)\n",
    "ax.set_title('Phase 1: ç»“æ„ç‰¹å¾åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "feature_plot_path = CONFIG['figures_dir'] / 'structural_features_distribution.png'\n",
    "plt.savefig(feature_plot_path, dpi=CONFIG['dpi'], bbox_inches='tight')\n",
    "print(f\"âœ“ å·²ä¿å­˜: {feature_plot_path.name}\")\n",
    "\n",
    "if CONFIG['display_plots']:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n",
    "\n",
    "print(f\"\\nâœ“ Phase 1 è´¨é‡éªŒè¯å®Œæˆï¼\")\n",
    "print(f\"  æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {CONFIG['figures_dir'].relative_to(project_root)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç»“æœæ€»ç»“ Summary\n",
    "\n",
    "Phase 1 æ•°æ®è½¬åŒ–å·²å®Œæˆï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Phase 1: æ•°æ®è½¬åŒ– - æ‰§è¡Œå®Œæ¯•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:\")\n",
    "print(f\"\\n  1. å¤„ç†åçš„CSV ({len(list(CONFIG['processed_dir'].glob('*.csv')))} ä¸ªæ–‡ä»¶):\")\n",
    "for f in sorted(CONFIG['processed_dir'].glob('*_processed.csv')):\n",
    "    print(f\"     - {f.name}\")\n",
    "\n",
    "print(f\"\\n  2. ç‰¹å¾NPZæ–‡ä»¶ ({len(list(CONFIG['features_dir'].glob('*.npz')))} ä¸ªæ–‡ä»¶):\")\n",
    "for f in sorted(CONFIG['features_dir'].glob('*.npz')):\n",
    "    size_mb = f.stat().st_size / 1024 / 1024\n",
    "    print(f\"     - {f.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(f\"\\n  3. éªŒè¯å›¾è¡¨ ({len(list(CONFIG['figures_dir'].glob('*.png')))} ä¸ªæ–‡ä»¶):\")\n",
    "for f in sorted(CONFIG['figures_dir'].glob('*.png')):\n",
    "    print(f\"     - {f.name}\")\n",
    "\n",
    "print(\"\\nğŸ“Š å¤„ç†ç»Ÿè®¡:\")\n",
    "total_original = summary_df['original_count'].sum()\n",
    "total_filtered = summary_df['filtered_count'].sum()\n",
    "retention_rate = total_filtered / total_original * 100\n",
    "\n",
    "print(f\"  åŸå§‹æ ·æœ¬æ€»æ•°: {total_original:,}\")\n",
    "print(f\"  ä¿ç•™æ ·æœ¬æ€»æ•°: {total_filtered:,} ({retention_rate:.1f}%)\")\n",
    "print(f\"  è¿‡æ»¤æ ·æœ¬æ•°: {total_original - total_filtered:,} ({100-retention_rate:.1f}%)\")\n",
    "print(f\"\\n  äºŒèšä½“æ ·æœ¬: {summary_df['dimer_count'].sum()} ({summary_df['dimer_count'].sum()/total_filtered*100:.1f}%)\")\n",
    "print(f\"  ç¯åŒ–æ ·æœ¬: {summary_df['cyclic_count'].sum()} ({summary_df['cyclic_count'].sum()/total_filtered*100:.1f}%)\")\n",
    "print(f\"  å«äºŒç¡«é”®æ ·æœ¬: {summary_df['disulfide_count'].sum()} ({summary_df['disulfide_count'].sum()/total_filtered*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâœ… ä¸‹ä¸€æ­¥: è¿è¡Œ Phase2_æ•°æ®å¯è§†åŒ–.ipynb\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
